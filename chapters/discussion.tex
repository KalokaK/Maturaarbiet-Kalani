\chapter{Discussion}\label{chap:discussion}
\section{Validity of Data}\label{sec:disc:significance}
The Error in win percentages between parameters variations is fairly low, games between agents are technically multinomial distributions but because ties are so infrequent (on average $\approx$ 0.5\% of outcomes), and all my data for win probabilities is close to 0.5, i use the "Wade" confidence interval of a binomial\cite[p. 2]{binomial_confidence} to approximate it. I accept a high error level\footnote{$1-\alpha$ can be thought of as the confidence that data falling outside the interval obtained with it, is meaningful.} of $\alpha = 0.2$, as this thesis' focus lies not in perfect parameters, but methods for agent training. The error obtained through this method turns out to be $\approx$0.013\footnote{$p \pm e, e = z\sqrt{p(1-p)/n}$ z is the number of standard deviations within which the percentage of data specified by $\alpha$ falls \cite[p. 2]{binomial_confidence}. It can be obtained by solving $1-\alpha = 2\int_0^z \sqrt{2\pi}^{-1}\exp(-t^2/2)dt$ for $z$.} which corresponds to 1.3\% for all parameters. This corresponds to a difference in elo between parameters of approximately 9\footnote{$\Delta elo = \log_{10}\left(\left(p_{win}^{-1}-1\right)^{-400}\right)$, this increases by $\approx$ 9.0 $\pm$ 0.5 for a percent error of 1 if $p_{win} = 0.5$ $\pm$ 0.12 which all of my data falls in to.} points. The more troublesome error is in the difference between between runs. I cannot control the random seed used for Unity, which makes 1 to 1 repeatability of runs impossible. Monte Carlo approximation of actual parameter performance is prohibitively expensive, instead I estimate the variance in runs as

\begin{equation*}
    \sigma^2 = \frac{1}{n-1} \sum_{i=1}^{n} \left( x_i - \overline{x} \right)^2
\end{equation*}

\noindent
and add to the variance in the binomial confidence interval. The variance of 8 sample runs at 10 million steps is $\approx$ 0.00035, corresponding to an error of $0.028 = 1.3\cdot \sqrt{p(1-p)/2560 + 0.00035}$ if $p_{win} = 0.5 \pm 0.12$, this holds for all my data. however this again imperfect as all data is interdependant. This can be mitigated by letting all sample agent's play against a common opponent, and using the average win percentage of the results for the variance, this methods yields: $\sigma^2 \approx 0.00010$, leading to an error of 0.018, again with $p_{win}$ = 0.5. This is perhaps more representative data as it more accurately reflects the scenario of comparison between parameters, it is the value which I will use, it corresponds to a $\Delta elo$ between parameters of $\approx 13.4$. 
\\Further, 20 million time steps might not be fully representative of agent performance after 100 million. For me, the computational cost of full training runs is simply too high. The elo rating system is a decent indicator of overall performance, but might not give the best parameter choice when testing.

\section{Training Process}
 Agent training for even a relatively simple problem such as this soccer simulation incurs immense computational and temporal cost, including initial testing, though much of this was in parallel, total training time during this thesis including initial testing was roughly 250 hours. Some of this was due to inefficiencies in my methodology, and perhaps poor code performance. As the training algorithm gets more complex and additional variables are introduced, this issue only worsens. 
 \\ Evaluation of training data is also quite difficult, especially in tasks where self play is involved. The elo rating system is a decent indicator of overall performance, but might not give the best parameter choice when testing.
\section{Results}

\section{Outlook}